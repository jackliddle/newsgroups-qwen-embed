{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# QWEN-3 Multi-Task Embeddings Tutorial\n\nThis notebook is a **tutorial** demonstrating how task-specific instructions affect embedding models.\n\n## What This Tutorial Shows\n\nWe explore how the same 800 documents from the 20 Newsgroups dataset are embedded using QWEN-3-Embedding-0.6B with **four different task instructions**:\n\n1. **Default** - No instruction (general-purpose embeddings)\n2. **Sentiment** - Optimized for sentiment classification\n3. **Topic** - Optimized for topic identification  \n4. **Toxicity** - Optimized for toxicity detection\n\nThe data has been pre-generated using `scripts/generate_data.py` and is ready to visualize.\n\n## Live Demo\n\nðŸ‘‰ **[View the interactive web demo](https://yourusername.github.io/newsgroups-qwen-embed/)**\n\nThe web app lets you switch between tasks and see how the embedding space changes."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport pandas as pd\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Understanding the Data\n\nThe data was generated using the following process:\n\n1. **Load Data**: 800 documents from 10 newsgroup categories (80 each)\n2. **Embed with Tasks**: Each document embedded 4 times with different instructions\n3. **Reduce Dimensions**: UMAP applied to each embedding set (1024D â†’ 2D)\n4. **Save as JSON**: All coordinates saved to `docs/data.json`\n\n### The Four Task Instructions\n\n| Task | Instruction |\n|------|------------|\n| **Default** | *(none)* - General-purpose embeddings |\n| **Sentiment** | \"Classify the sentiment of the given text as positive, negative, or neutral\" |\n| **Topic** | \"Identify the topic or theme of the given text\" |\n| **Toxicity** | \"Classify the given text as either toxic or not toxic\" |\n\n### The Categories\n\nThe 10 newsgroup categories cover diverse topics:\n\n- **Religious/Political**: alt.atheism, talk.religion.misc, talk.politics.guns, talk.politics.mideast\n- **Scientific/Technical**: sci.med, sci.space, sci.crypt, comp.graphics  \n- **Recreation**: rec.sport.baseball, rec.autos"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the pre-generated data\nwith open('docs/data.json', 'r') as f:\n    data = json.load(f)\n\n# Convert to DataFrame for easier manipulation\ndf = pd.DataFrame(data)\n\nprint(f\"Loaded {len(df)} documents\")\nprint(f\"\\nColumns: {df.columns.tolist()}\")\nprint(f\"\\nCategories: {df['category'].unique()}\")\nprint(f\"\\nCategory distribution:\")\nprint(df['category'].value_counts())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Preview a sample document\nsample = df.iloc[0]\n\nprint(\"Sample Document:\")\nprint(f\"Category: {sample['category']}\")\nprint(f\"\\nText preview:\\n{sample['text_preview']}\")\nprint(f\"\\nCoordinates:\")\nprint(f\"  Default: ({sample['default_x']:.3f}, {sample['default_y']:.3f})\")\nprint(f\"  Sentiment: ({sample['sentiment_x']:.3f}, {sample['sentiment_y']:.3f})\")\nprint(f\"  Topic: ({sample['topic_x']:.3f}, {sample['topic_y']:.3f})\")\nprint(f\"  Toxicity: ({sample['toxicity_x']:.3f}, {sample['toxicity_y']:.3f})\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Visualizing Task-Specific Embeddings\n\nNow let's visualize how the different task instructions affect the embedding space.\n\nEach point represents a document, colored by its newsgroup category. The positions show how QWEN-3 organizes documents based on the task instruction."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Create 4-panel comparison visualization\n\n# Task titles for display\ntask_titles = {\n    'default': 'Default (No Instruction)',\n    'sentiment': 'Sentiment Task',\n    'topic': 'Topic Classification Task',\n    'toxicity': 'Toxicity Detection Task'\n}\n\nfig = make_subplots(\n    rows=1, cols=4,\n    subplot_titles=[task_titles[task] for task in ['default', 'sentiment', 'topic', 'toxicity']],\n    horizontal_spacing=0.05\n)\n\n# Create a plot for each task\nfor col_idx, task_name in enumerate(['default', 'sentiment', 'topic', 'toxicity'], start=1):\n    for category in df['category'].unique():\n        mask = df['category'] == category\n        fig.add_trace(\n            go.Scatter(\n                x=df[mask][f'{task_name}_x'],\n                y=df[mask][f'{task_name}_y'],\n                mode='markers',\n                name=category,\n                marker=dict(\n                    size=6,\n                    opacity=0.7,\n                    line=dict(width=0.5, color='white')\n                ),\n                text=df[mask]['text_preview'],\n                hovertemplate='<b>%{fullData.name}</b><br><br>%{text}<br><extra></extra>',\n                legendgroup=category,\n                showlegend=(col_idx == 1)  # Only show legend for first plot\n            ),\n            row=1, col=col_idx\n        )\n\n# Update layout\nfig.update_layout(\n    title_text='QWEN-3 Multi-Task Embedding Comparison (UMAP Projection)',\n    title_x=0.5,\n    height=600,\n    width=2400,\n    hovermode='closest',\n    legend=dict(\n        yanchor=\"top\",\n        y=0.99,\n        xanchor=\"left\",\n        x=1.01,\n        title=\"Newsgroup Category\"\n    )\n)\n\n# Update axes labels\nfor col_idx in range(1, 5):\n    fig.update_xaxes(title_text=\"UMAP Dimension 1\", row=1, col=col_idx)\n    fig.update_yaxes(title_text=\"UMAP Dimension 2\", row=1, col=col_idx)\n\nfig.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 3. Understanding the Results\n\n### What to Look For\n\nWhen comparing the four plots above, observe:\n\n1. **Cluster Quality**: Which task creates the clearest separation between newsgroup categories?\n\n2. **Task Alignment**: The **Topic task** should produce the best category separation since identifying topics aligns naturally with classifying newsgroups.\n\n3. **Semantic Reorganization**: Notice how the same documents occupy different positions across tasks. The embedding space is literally \"reshaped\" by the instruction.\n\n4. **Cross-Category Patterns**: \n   - **Sentiment**: May group texts by emotional tone rather than subject matter\n   - **Toxicity**: Political/religious groups might show different patterns than technical/hobby groups\n   - **Default**: Provides balanced, general-purpose organization\n\n### Key Insight\n\n**Task instructions are powerful!** The same model, same documents, but different instructions create fundamentally different embedding spaces. Choose your instruction based on your downstream task.\n\n### Why This Matters\n\nWhen building applications with embeddings:\n- **Search/Retrieval**: Use task-specific instructions matching your search intent\n- **Classification**: Align the instruction with your classification goal\n- **Clustering**: Consider what dimension you want documents grouped by\n- **Similarity**: Define \"similar\" via the task instruction\n\n### Technical Details\n\n- **Model**: QWEN-3-Embedding-0.6B (1024 dimensions)\n- **Reduction**: UMAP (n_neighbors=15, min_dist=0.1, random_state=42)\n- **Documents**: 800 (80 per category, stratified sampling)\n- **API**: SiliconFlow\n- **Format**: `\"Instruct: {instruction}\\nQuery: {text}\"` (for non-default tasks)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Try It Yourself\n\n### Option A: Explore the Web Demo\n\nThe interactive web app (`docs/index.html`) lets you:\n- Click buttons to switch between tasks\n- Hover over points to read document previews\n- See task instructions and explanations\n\n### Option B: Generate New Data\n\nTo regenerate the embeddings or try different tasks:\n\n```bash\n# Edit scripts/generate_data.py to modify tasks or parameters\npoetry run python scripts/generate_data.py\n```\n\nYou can experiment with:\n- Different task instructions (see `task_prompts.json` for examples)\n- More/fewer documents\n- Different UMAP parameters\n- Additional newsgroup categories\n\n### Option C: Analyze Specific Tasks\n\nCreate individual plots to dive deeper into one task:"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Example: Focus on the Topic task\nfig_topic = px.scatter(\n    df,\n    x='topic_x',\n    y='topic_y',\n    color='category',\n    hover_data={'text_preview': True, 'topic_x': False, 'topic_y': False, 'category': False},\n    title='Topic Classification Task - UMAP Projection',\n    width=1000,\n    height=700\n)\n\nfig_topic.update_traces(\n    marker=dict(size=8, opacity=0.7, line=dict(width=0.5, color='white')),\n    hovertemplate='<b>%{fullData.name}</b><br><br>%{customdata[0]}<br><extra></extra>'\n)\n\nfig_topic.update_layout(\n    hovermode='closest',\n    xaxis_title=\"UMAP Dimension 1\",\n    yaxis_title=\"UMAP Dimension 2\"\n)\n\nfig_topic.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## 5. Further Exploration\n\n### Questions to Investigate\n\n1. **Which categories are most similar?**\n   - Look for overlapping clusters in the topic task\n   - Are religious and political groups close together?\n   - Do scientific categories form a distinct region?\n\n2. **How does sentiment vary by category?**\n   - Switch to the sentiment plot\n   - Do political newsgroups show more extreme sentiment than technical ones?\n   - Are hobby groups (baseball, autos) more positive?\n\n3. **Toxicity patterns across topics**\n   - Political discussions (guns, mideast) vs technical discussions (graphics, crypto)\n   - Does toxicity correlate with sentiment, or are they independent?\n\n4. **Default vs Task-Specific**\n   - How much does the topic instruction help compared to default?\n   - When would you prefer default embeddings over task-specific ones?\n\n### Next Steps\n\n- **Try other QWEN tasks**: emotion classification, semantic similarity, query-document matching\n- **Compare models**: How does QWEN-3-0.6B compare to the 1.5B model?\n- **Build applications**: Use task instructions in your own search, recommendation, or classification systems\n- **Explore the code**: Check `qwen_embedder.py` for the async batching implementation\n\n### Resources\n\n- [QWEN-3 Embedding Documentation](./QWEN-EMBED.md)\n- [Task Prompt Examples](./task_prompts.json)\n- [Official QWEN Repo](https://github.com/QwenLM/Qwen3-Embedding)\n- [SiliconFlow API](https://siliconflow.com)\n- [20 Newsgroups Dataset](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Multi-Task Visualization Comparison\n\nCreate 4-panel visualization comparing how different task instructions affect the embedding space."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 5. Individual Task Plots for Detailed Exploration"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Sentiment task embeddings plot\nfig_sentiment = px.scatter(\n    df,\n    x='sentiment_x',\n    y='sentiment_y',\n    color='category',\n    hover_data={'text_preview': True, 'sentiment_x': False, 'sentiment_y': False, 'category': False},\n    title='Sentiment Task Embeddings - UMAP Projection',\n    width=900,\n    height=700,\n    color_discrete_map=color_map\n)\n\nfig_sentiment.update_traces(\n    marker=dict(size=8, opacity=0.7, line=dict(width=0.5, color='white')),\n    hovertemplate='<b>%{fullData.name}</b><br><br>%{customdata[0]}<br><extra></extra>'\n)\n\nfig_sentiment.update_layout(hovermode='closest')\nfig_sentiment.show()"
  },
  {
   "cell_type": "code",
   "source": "# Toxicity task embeddings plot\nfig_toxicity = px.scatter(\n    df,\n    x='toxicity_x',\n    y='toxicity_y',\n    color='category',\n    hover_data={'text_preview': True, 'toxicity_x': False, 'toxicity_y': False, 'category': False},\n    title='Toxicity Detection Task Embeddings - UMAP Projection',\n    width=900,\n    height=700,\n    color_discrete_map=color_map\n)\n\nfig_toxicity.update_traces(\n    marker=dict(size=8, opacity=0.7, line=dict(width=0.5, color='white')),\n    hovertemplate='<b>%{fullData.name}</b><br><br>%{customdata[0]}<br><extra></extra>'\n)\n\nfig_toxicity.update_layout(hovermode='closest')\nfig_toxicity.show()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Save interactive HTML files\nviz_dir = Path('visualizations')\nviz_dir.mkdir(exist_ok=True)\n\n# Save comparison and individual plots\nfig.write_html(viz_dir / 'multitask_comparison.html')\nfig_default.write_html(viz_dir / 'default_embeddings.html')\nfig_sentiment.write_html(viz_dir / 'sentiment_embeddings.html')\nfig_topic.write_html(viz_dir / 'topic_embeddings.html')\nfig_toxicity.write_html(viz_dir / 'toxicity_embeddings.html')\n\nprint(\"Saved visualizations to:\", viz_dir.absolute())\nprint(\"\\nFiles created:\")\nprint(\"  - multitask_comparison.html (4-panel comparison)\")\nprint(\"  - default_embeddings.html\")\nprint(\"  - sentiment_embeddings.html\")\nprint(\"  - topic_embeddings.html\")\nprint(\"  - toxicity_embeddings.html\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newsgroups-qwen-embed-stTfPPiI-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}