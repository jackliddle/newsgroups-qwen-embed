{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# QWEN-3 Task-Specific Embeddings Demo\n\nThis notebook demonstrates how **task-specific instructions** reshape the embedding space of QWEN-3 models.\n\n## What We'll Do\n\nWe'll embed 800 documents from the 20 Newsgroups dataset using two approaches:\n\n1. **Default Embeddings** - No instruction (general-purpose)\n2. **Sentiment Embeddings** - With instruction: \"Classify the sentiment of the given text as positive, negative, or neutral\"\n\nThen we'll compare how the embedding space changes based on the task instruction.\n\n## Key Insight\n\nThe same model, same documents, but different instructions create fundamentally different embedding spaces. This is powerful for building applications where you want embeddings optimized for specific downstream tasks."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "import umap\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from qwen_embedder import QwenEmbedder, QwenModel, EmbeddingConfig\n",
    "\n",
    "print(\"‚úì Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Preprocess Data\n",
    "\n",
    "We'll load 10 newsgroup categories covering diverse topics:\n",
    "- Religious/Political: alt.atheism, talk.religion.misc, talk.politics.guns, talk.politics.mideast\n",
    "- Scientific/Technical: sci.med, sci.space, sci.crypt, comp.graphics\n",
    "- Recreation: rec.sport.baseball, rec.autos\n",
    "\n",
    "We'll sample 80 documents per category for a total of 800 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categories\n",
    "CATEGORIES = [\n",
    "    'alt.atheism',\n",
    "    'comp.graphics',\n",
    "    'sci.med',\n",
    "    'talk.religion.misc',\n",
    "    'rec.sport.baseball',\n",
    "    'sci.space',\n",
    "    'talk.politics.guns',\n",
    "    'talk.politics.mideast',\n",
    "    'rec.autos',\n",
    "    'sci.crypt'\n",
    "]\n",
    "\n",
    "print(f\"Loading 20 Newsgroups dataset ({len(CATEGORIES)} categories)...\")\n",
    "\n",
    "newsgroups = fetch_20newsgroups(\n",
    "    subset='all',\n",
    "    categories=CATEGORIES,\n",
    "    remove=('headers', 'footers', 'quotes'),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'text': newsgroups.data,\n",
    "    'category': [newsgroups.target_names[i] for i in newsgroups.target]\n",
    "})\n",
    "\n",
    "# Clean and filter text\n",
    "df['text_clean'] = df['text'].str.replace(r'\\s+', ' ', regex=True).str.strip()\n",
    "df = df[df['text_clean'].str.len() >= 100].copy()  # Remove very short posts\n",
    "df['text_clean'] = df['text_clean'].str[:5000]  # Truncate very long posts\n",
    "\n",
    "# Stratified sampling: 80 documents per category\n",
    "df_sampled = df.groupby('category', group_keys=False).apply(\n",
    "    lambda x: x.sample(n=min(80, len(x)), random_state=42)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Create preview for hover tooltips\n",
    "df_sampled['text_preview'] = df_sampled['text_clean'].str[:200] + '...'\n",
    "\n",
    "print(f\"\\n‚úì Loaded {len(df_sampled)} documents\")\n",
    "print(f\"\\nCategory distribution:\")\n",
    "print(df_sampled['category'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview a sample document\n",
    "sample = df_sampled.iloc[0]\n",
    "print(f\"Sample Document:\")\n",
    "print(f\"Category: {sample['category']}\")\n",
    "print(f\"\\nText preview:\\n{sample['text_preview']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. Generate Embeddings with Two Tasks\n\nNow we'll embed all 800 documents **twice**:\n\n### Task 1: Default Embeddings\nNo instruction provided - general-purpose embeddings that capture overall semantic meaning.\n\n### Task 2: Sentiment Embeddings\nInstruction: \"Classify the sentiment of the given text as positive, negative, or neutral\"\n\nThis tells QWEN-3 to focus on emotional tone and polarity when creating embeddings.\n\n---\n\n**Note**: This step calls the SiliconFlow API. Progress bars will show embedding generation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure embedder\n",
    "config = EmbeddingConfig(\n",
    "    model=QwenModel.SMALL,  # QWEN-3-Embedding-0.6B\n",
    "    batch_size=32,\n",
    "    max_concurrent=10\n",
    ")\n",
    "\n",
    "print(\"Initialized QWEN-3 Embedder\")\n",
    "print(f\"Model: {config.model.value}\")\n",
    "print(f\"Batch size: {config.batch_size}\")\n",
    "print(f\"Max concurrent requests: {config.max_concurrent}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed all documents with both tasks\n",
    "async def generate_embeddings():\n",
    "    \"\"\"Generate embeddings for both tasks.\"\"\"\n",
    "    texts = df_sampled['text_clean'].tolist()\n",
    "    \n",
    "    all_embeddings = {}\n",
    "    \n",
    "    async with QwenEmbedder(config=config) as embedder:\n",
    "        # Task 1: Default (no instruction)\n",
    "        print(\"=\"*60)\n",
    "        print(\"TASK 1: DEFAULT EMBEDDINGS (No Instruction)\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        embeddings_default = await embedder.embed_async(\n",
    "            texts,\n",
    "            task_instruction=None,\n",
    "            show_progress=True\n",
    "        )\n",
    "        all_embeddings['default'] = np.array(embeddings_default)\n",
    "        print(f\"‚úì Generated {len(embeddings_default)} default embeddings (dim={len(embeddings_default[0])})\\n\")\n",
    "        \n",
    "        # Task 2: Sentiment\n",
    "        print(\"=\"*60)\n",
    "        print(\"TASK 2: SENTIMENT EMBEDDINGS\")\n",
    "        print(\"Instruction: 'Classify the sentiment of the given text as positive, negative, or neutral'\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        embeddings_sentiment = await embedder.embed_async(\n",
    "            texts,\n",
    "            task_instruction=\"Classify the sentiment of the given text as positive, negative, or neutral\",\n",
    "            show_progress=True\n",
    "        )\n",
    "        all_embeddings['sentiment'] = np.array(embeddings_sentiment)\n",
    "        print(f\"‚úì Generated {len(embeddings_sentiment)} sentiment embeddings (dim={len(embeddings_sentiment[0])})\\n\")\n",
    "    \n",
    "    return all_embeddings\n",
    "\n",
    "# Run the async function\n",
    "all_embeddings = await generate_embeddings()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úì EMBEDDING GENERATION COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Apply UMAP Dimensionality Reduction\n",
    "\n",
    "Our embeddings are 1024-dimensional vectors. To visualize them, we'll reduce them to 2D using UMAP.\n",
    "\n",
    "UMAP (Uniform Manifold Approximation and Projection) preserves both local and global structure, making it ideal for visualizing embedding spaces.\n",
    "\n",
    "We'll apply UMAP separately to each task's embeddings to see how the 2D projections differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Applying UMAP dimensionality reduction...\\n\")\n",
    "\n",
    "umap_coords = {}\n",
    "\n",
    "for task_name in ['default', 'sentiment']:\n",
    "    print(f\"  Processing {task_name} embeddings...\")\n",
    "    \n",
    "    reducer = umap.UMAP(\n",
    "        n_components=2,\n",
    "        n_neighbors=15,\n",
    "        min_dist=0.1,\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    coords = reducer.fit_transform(all_embeddings[task_name])\n",
    "    umap_coords[task_name] = coords\n",
    "    \n",
    "    # Add to dataframe\n",
    "    df_sampled[f'{task_name}_x'] = coords[:, 0]\n",
    "    df_sampled[f'{task_name}_y'] = coords[:, 1]\n",
    "    \n",
    "    print(f\"  ‚úì {task_name}: reduced to {coords.shape}\")\n",
    "\n",
    "print(\"\\n‚úì UMAP reduction complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize: Default vs Sentiment Embeddings\n",
    "\n",
    "Now let's create a side-by-side comparison of the two embedding spaces.\n",
    "\n",
    "Each point represents one document, colored by its newsgroup category. Hover over points to see the text preview.\n",
    "\n",
    "### What to Look For\n",
    "\n",
    "- **Default (left)**: General-purpose organization based on overall semantic similarity\n",
    "- **Sentiment (right)**: Organization based on emotional tone and polarity\n",
    "\n",
    "Notice how the same documents occupy different positions in the two spaces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2-panel comparison\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=2,\n",
    "    subplot_titles=['Default Embeddings (No Instruction)', 'Sentiment Embeddings'],\n",
    "    horizontal_spacing=0.08\n",
    ")\n",
    "\n",
    "# Plot both tasks\n",
    "for col_idx, task_name in enumerate(['default', 'sentiment'], start=1):\n",
    "    for category in df_sampled['category'].unique():\n",
    "        mask = df_sampled['category'] == category\n",
    "        \n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df_sampled[mask][f'{task_name}_x'],\n",
    "                y=df_sampled[mask][f'{task_name}_y'],\n",
    "                mode='markers',\n",
    "                name=category,\n",
    "                marker=dict(\n",
    "                    size=7,\n",
    "                    opacity=0.7,\n",
    "                    line=dict(width=0.5, color='white')\n",
    "                ),\n",
    "                text=df_sampled[mask]['text_preview'],\n",
    "                hovertemplate='<b>%{fullData.name}</b><br><br>%{text}<br><extra></extra>',\n",
    "                legendgroup=category,\n",
    "                showlegend=(col_idx == 1)  # Only show legend once\n",
    "            ),\n",
    "            row=1, col=col_idx\n",
    "        )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text='How Task Instructions Reshape Embeddings: Default vs Sentiment',\n",
    "    title_x=0.5,\n",
    "    title_font_size=18,\n",
    "    height=700,\n",
    "    width=1800,\n",
    "    hovermode='closest',\n",
    "    legend=dict(\n",
    "        yanchor=\"top\",\n",
    "        y=0.99,\n",
    "        xanchor=\"left\",\n",
    "        x=1.01,\n",
    "        title=\"Newsgroup Category\",\n",
    "        font=dict(size=11)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Update axes\n",
    "for col_idx in range(1, 3):\n",
    "    fig.update_xaxes(title_text=\"UMAP Dimension 1\", row=1, col=col_idx)\n",
    "    fig.update_yaxes(title_text=\"UMAP Dimension 2\", row=1, col=col_idx)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Analysis and Key Takeaways\n",
    "\n",
    "### Observations\n",
    "\n",
    "Compare the two plots above:\n",
    "\n",
    "1. **Cluster Quality**: Which embedding space creates clearer separation between newsgroup categories?\n",
    "   - The **default embeddings** (left) likely show better category separation since they're optimized for general semantic similarity\n",
    "   - The **sentiment embeddings** (right) may group documents by emotional tone rather than topic\n",
    "\n",
    "2. **Semantic Reorganization**: The same documents occupy different positions in the two spaces\n",
    "   - A political post and a sports post might be far apart in default space but close together in sentiment space if both are positive\n",
    "   - This shows how task instructions literally \"reshape\" the embedding geometry\n",
    "\n",
    "3. **Cross-Category Patterns**:\n",
    "   - Do political newsgroups (guns, mideast) cluster together in sentiment space?\n",
    "   - Are technical discussions (graphics, crypto) more neutral in sentiment?\n",
    "   - Do hobby groups (baseball, autos) lean more positive?\n",
    "\n",
    "### Key Insight: Task Instructions Are Powerful!\n",
    "\n",
    "The same model, same documents, but different instructions create fundamentally different embedding spaces.\n",
    "\n",
    "**When building applications:**\n",
    "- üîç **Search/Retrieval**: Use task instructions matching your search intent\n",
    "- üìä **Classification**: Align the instruction with your classification goal\n",
    "- üéØ **Clustering**: Choose task based on how you want documents grouped\n",
    "- ‚ÜîÔ∏è **Similarity**: Define \"similar\" via the task instruction\n",
    "\n",
    "### Technical Details\n",
    "\n",
    "- **Model**: QWEN-3-Embedding-0.6B (1024 dimensions)\n",
    "- **Reduction**: UMAP (n_neighbors=15, min_dist=0.1, random_state=42)\n",
    "- **Documents**: 800 (80 per category, stratified sampling)\n",
    "- **API**: SiliconFlow\n",
    "- **Format**: `\"Instruct: {instruction}\\nQuery: {text}\"` (for sentiment task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Next Steps\n",
    "\n",
    "### Try Different Tasks\n",
    "\n",
    "Modify the sentiment instruction to explore other tasks:\n",
    "\n",
    "```python\n",
    "# Topic classification\n",
    "\"Identify the topic or theme of the given text\"\n",
    "\n",
    "# Toxicity detection\n",
    "\"Classify the given text as either toxic or not toxic\"\n",
    "\n",
    "# Emotion recognition\n",
    "\"Classify the emotion expressed in the given text\"\n",
    "\n",
    "# Query-document matching\n",
    "\"Given a web search query, retrieve relevant passages that answer the query\"\n",
    "```\n",
    "\n",
    "### Experiment with Parameters\n",
    "\n",
    "- Try different newsgroup categories\n",
    "- Adjust sample size (more/fewer documents)\n",
    "- Modify UMAP parameters (n_neighbors, min_dist)\n",
    "- Compare QWEN-3-0.6B vs larger models\n",
    "\n",
    "### Deploy to Web\n",
    "\n",
    "Use `scripts/generate_data.py` to create the full web app:\n",
    "\n",
    "```bash\n",
    "poetry run python scripts/generate_data.py\n",
    "```\n",
    "\n",
    "Then open `docs/index.html` for an interactive version!\n",
    "\n",
    "### Build Applications\n",
    "\n",
    "- **Semantic search** with task-specific embeddings\n",
    "- **Document classification** using instruction-tuned embeddings\n",
    "- **Recommendation systems** that understand context\n",
    "- **Content moderation** with toxicity-focused embeddings\n",
    "\n",
    "### Resources\n",
    "\n",
    "- [QWEN-3 Embedding arXiv Paper](https://arxiv.org/abs/2506.05176)\n",
    "- [Official QWEN Repository](https://github.com/QwenLM/Qwen3-Embedding)\n",
    "- [SiliconFlow API Docs](https://siliconflow.com)\n",
    "- [20 Newsgroups Dataset](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset)\n",
    "- [UMAP Documentation](https://umap-learn.readthedocs.io/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}